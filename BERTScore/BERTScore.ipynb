{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERTScore.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFbf-XO9EfGy"
      },
      "source": [
        "## `BERTScore` metric with `BERT` alternatives "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7i1TNmTFbY8",
        "outputId": "0ae3394a-6773-46c4-f1b7-54453c1f8836"
      },
      "source": [
        "!pip install bert_score"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.10-py3-none-any.whl (59 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▌                          | 10 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 20 kB 33.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 30 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 40 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 51 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 59 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from bert_score) (1.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bert_score) (2.23.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from bert_score) (3.2.2)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from bert_score) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.7/dist-packages (from bert_score) (4.62.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from bert_score) (21.0)\n",
            "Collecting transformers>=3.0.0numpy\n",
            "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 18.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->bert_score) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert_score) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert_score) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert_score) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->bert_score) (3.7.4.3)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 62.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 70.0 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 68.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (4.6.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.0.0numpy->bert_score) (3.5.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert_score) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert_score) (1.3.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.0numpy->bert_score) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.0numpy->bert_score) (7.1.2)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers, bert-score\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed bert-score-0.3.10 huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bLvzwIWxFbZG",
        "outputId": "1918b89f-b92d-4a97-ed01-158545f30443"
      },
      "source": [
        "# check installation\n",
        "import bert_score\n",
        "bert_score.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.3.10'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNDlbaEmFbZN"
      },
      "source": [
        "import transformers\n",
        "import tracemalloc\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from time import perf_counter\n",
        "from bert_score import score\n",
        "from scipy.stats import pearsonr"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFh0dB55bzSu",
        "outputId": "01ec9ee2-3fa7-48bd-9e86-e0611326cd72"
      },
      "source": [
        "# get dataset\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "dpath = \"/content/drive/MyDrive/data/MSE/scores_deen.csv\"\n",
        "df = pd.read_csv(dpath, usecols=['mt', 'ref', 'raw_score'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GhqtOjjcO9O"
      },
      "source": [
        "translations = df.mt.tolist()\n",
        "references = df.ref.tolist()\n",
        "raw_scores = df.raw_score.tolist()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHlJcFi3FbZs"
      },
      "source": [
        "Calculating scores\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELKXECA-2aiA"
      },
      "source": [
        "VARIANT = 'Variant'\n",
        "CORRELATION = 'Pearson Corr.'\n",
        "TIME = 'Time F1 Score'\n",
        "BERTTIME = '% Time BERT'\n",
        "MEMORY = 'max Memory Usage'\n",
        "BERTMEM = '% Memory BERT'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idNWv2tq0MXA"
      },
      "source": [
        "def get_variants():\n",
        "  \"\"\"\n",
        "  defines bert variants to test and builds an empty dict of all necessary  values\n",
        "  :returns: variants (list): list of BERT variants to test on\n",
        "  :returns: results (dict): dict of value : empty list to fill in\n",
        "  \"\"\"\n",
        "  variants = [\"bert-base-uncased\", \"roberta-base\", \"albert-base-v2\", \"distilbert-base-uncased\", \"microsoft/deberta-base\"]\n",
        "  results = {\n",
        "      VARIANT: [],\n",
        "      CORRELATION: [],\n",
        "      TIME: [],\n",
        "      BERTTIME: [],\n",
        "      MEMORY: [],\n",
        "      BERTMEM: []\n",
        "  }\n",
        "  return variants, results"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WzWTZiXEsx2"
      },
      "source": [
        "def get_scores(cands, refs, raw_scores, idf):\n",
        "  \"\"\"\n",
        "  calculates scores for given references and translations and a pearson correlation\n",
        "  with human scores\n",
        "  :param:   refs (list): list of reference translations\n",
        "  :param:   cands (list): list of machine translations\n",
        "  :param:   raw_scores (list): list of human scores between references and mt\n",
        "  :param:   idf (Boolean): whether to use idf importance weighting\n",
        "  :returns: results (dict): dict of variant, time and memory footprint and correlation\n",
        "  \"\"\"\n",
        "  variants, results = get_variants()\n",
        "  for v in variants:\n",
        "    F1_scores = []\n",
        "    results[VARIANT].append(v)\n",
        "    tracemalloc.start()\n",
        "    s = perf_counter()\n",
        "    _, _, F1 = score(cands, refs, lang='en', model_type=v, idf=idf)\n",
        "    F1_scores.append(F1)\n",
        "    if (i+1) % 100 == 0:\n",
        "      print(f'Done: {i+1}, in {v}')\n",
        "    results[TIME].append(perf_counter() - s)\n",
        "    current, peak = tracemalloc.get_traced_memory()\n",
        "    print(f'Current memory usage for {v} is {current / 10**6}MB; Peak was {peak / 10**6}MB, time taken {perf_counter() - s:.2f} s ({(perf_counter() - s) /60:.2f} min)')\n",
        "    tracemalloc.stop()\n",
        "    results[MEMORY].append(peak)\n",
        "    assert len(F1) == len(raw_scores), f\"Scores are not of the same length, (F1: {F1_scores}, human: {raw_scores})\"\n",
        "    corr, _ = pearsonr(F1, raw_scores)\n",
        "\n",
        "    results[CORRELATION].append(f'{corr:.3f}')\n",
        "  return results"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz3MBQLPIlFz"
      },
      "source": [
        "# ignore warning messages from transformers\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from transformers import logging\n",
        "\n",
        "logging.set_verbosity_error()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPScfsDERLpx"
      },
      "source": [
        "# zip translations, references and according scores together\n",
        "d_set = list(zip(translations, references, raw_scores))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZSZm06SceUF",
        "outputId": "c05f2a21-42ca-4188-afa6-a5ff5518de6d"
      },
      "source": [
        "# limited number of examples due to colab limitations\n",
        "num_ex = 10000\n",
        "n = 5\n",
        "res = {}\n",
        "# iterate over samples of given data\n",
        "for i in range(n):\n",
        "  sample = random.sample(d_set, num_ex)\n",
        "  t, r, s = zip(*sample)\n",
        "  print(f'Iteration {i+1}')\n",
        "  res[i] = get_scores(t, r, s, idf=True)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1\n",
            "Current memory usage for bert-base-uncased is 38.823393MB; Peak was 60.366585MB, time taken 44.29 s (0.74 min)\n",
            "Current memory usage for roberta-base is 28.636529MB; Peak was 54.927814MB, time taken 42.06 s (0.70 min)\n",
            "Current memory usage for albert-base-v2 is 0.174684MB; Peak was 19.734051MB, time taken 34.08 s (0.57 min)\n",
            "Current memory usage for distilbert-base-uncased is 9.411342MB; Peak was 30.974451MB, time taken 33.80 s (0.56 min)\n",
            "Current memory usage for microsoft/deberta-base is 28.609074MB; Peak was 56.187488MB, time taken 44.90 s (0.75 min)\n",
            "Iteration 2\n",
            "Current memory usage for bert-base-uncased is 9.805145MB; Peak was 31.455536MB, time taken 44.02 s (0.73 min)\n",
            "Current memory usage for roberta-base is 0.223263MB; Peak was 54.968443MB, time taken 42.70 s (0.71 min)\n",
            "Current memory usage for albert-base-v2 is 0.163775MB; Peak was 19.818513MB, time taken 34.79 s (0.58 min)\n",
            "Current memory usage for distilbert-base-uncased is 9.408906MB; Peak was 31.074832MB, time taken 34.53 s (0.58 min)\n",
            "Current memory usage for microsoft/deberta-base is 0.262651MB; Peak was 54.995048MB, time taken 45.83 s (0.76 min)\n",
            "Iteration 3\n",
            "Current memory usage for bert-base-uncased is 0.351236MB; Peak was 31.432351MB, time taken 44.27 s (0.74 min)\n",
            "Current memory usage for roberta-base is 0.220069MB; Peak was 54.959376MB, time taken 43.05 s (0.72 min)\n",
            "Current memory usage for albert-base-v2 is 1.168777MB; Peak was 19.793941MB, time taken 34.70 s (0.58 min)\n",
            "Current memory usage for distilbert-base-uncased is 0.235198MB; Peak was 31.074655MB, time taken 34.56 s (0.58 min)\n",
            "Current memory usage for microsoft/deberta-base is 0.268037MB; Peak was 54.919132MB, time taken 45.71 s (0.76 min)\n",
            "Iteration 4\n",
            "Current memory usage for bert-base-uncased is 9.791054MB; Peak was 31.465159MB, time taken 43.85 s (0.73 min)\n",
            "Current memory usage for roberta-base is 0.230105MB; Peak was 54.980028MB, time taken 43.03 s (0.72 min)\n",
            "Current memory usage for albert-base-v2 is 0.146354MB; Peak was 19.818156MB, time taken 34.67 s (0.58 min)\n",
            "Current memory usage for distilbert-base-uncased is 0.255632MB; Peak was 31.106461MB, time taken 34.52 s (0.58 min)\n",
            "Current memory usage for microsoft/deberta-base is 0.237778MB; Peak was 54.943234MB, time taken 45.56 s (0.76 min)\n",
            "Iteration 5\n",
            "Current memory usage for bert-base-uncased is 0.34095MB; Peak was 31.436144MB, time taken 43.55 s (0.73 min)\n",
            "Current memory usage for roberta-base is 0.218621MB; Peak was 56.482973MB, time taken 42.51 s (0.71 min)\n",
            "Current memory usage for albert-base-v2 is 0.17214MB; Peak was 19.808028MB, time taken 34.37 s (0.57 min)\n",
            "Current memory usage for distilbert-base-uncased is 9.413069MB; Peak was 31.060521MB, time taken 33.82 s (0.56 min)\n",
            "Current memory usage for microsoft/deberta-base is 0.224323MB; Peak was 56.227877MB, time taken 45.26 s (0.75 min)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbM8mKTAh2Tc"
      },
      "source": [
        "# combine multiple runs into average DataFrame\n",
        "df_list = []\n",
        "for i in range(n):\n",
        "  try:\n",
        "    del res[i][BERTMEM]\n",
        "    del res[i][BERTTIME]\n",
        "  except:\n",
        "    pass  \n",
        "  df_list.append(pd.DataFrame.from_dict(res[i]).astype({'Pearson Corr.': 'float64'}))\n",
        "# print(df_list, type(df_list))\n",
        "df = pd.concat(df_list)\n",
        "average = df.groupby(VARIANT, sort=False, as_index=False).mean()\n",
        "results = pd.DataFrame.to_dict(average, orient='list')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKGQeRvGPZ8_"
      },
      "source": [
        "# compare time taken to base bert time\n",
        "variants = [\"bert-base-uncased\", \"roberta-base\", \"albert-base-v2\", \"distilbert-base-uncased\", \"microsoft/deberta-base\"]\n",
        "\n",
        "results[BERTTIME] = []\n",
        "results[BERTMEM] = []\n",
        "for i in range(len(variants)):\n",
        "  results[BERTTIME].append(f'{results[TIME][i] / results[TIME][0] * 100:.1f}')\n",
        "  results[BERTMEM].append(f'{results[MEMORY][i] / results[MEMORY][0] * 100:.1f}')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q569fALX4VN"
      },
      "source": [
        "# build and save dataframe\n",
        "df = pd.DataFrame(results, columns=[VARIANT, CORRELATION, BERTTIME, BERTMEM]).set_index(VARIANT)\n",
        "df.to_csv(\"BERTScore_results.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4bmENYt09I3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "d6bd8f45-4409-4332-f21b-07fe7f0c96a1"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pearson Corr.</th>\n",
              "      <th>% Time BERT</th>\n",
              "      <th>% Memory BERT</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bert-base-uncased</th>\n",
              "      <td>0.3494</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>roberta-base</th>\n",
              "      <td>0.3550</td>\n",
              "      <td>111.5</td>\n",
              "      <td>276.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>albert-base-v2</th>\n",
              "      <td>0.3444</td>\n",
              "      <td>79.1</td>\n",
              "      <td>35.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>distilbert-base-uncased</th>\n",
              "      <td>0.3496</td>\n",
              "      <td>79.7</td>\n",
              "      <td>99.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>microsoft/deberta-base</th>\n",
              "      <td>0.3592</td>\n",
              "      <td>115.5</td>\n",
              "      <td>275.7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Pearson Corr. % Time BERT % Memory BERT\n",
              "Variant                                                         \n",
              "bert-base-uncased               0.3494       100.0         100.0\n",
              "roberta-base                    0.3550       111.5         276.7\n",
              "albert-base-v2                  0.3444        79.1          35.9\n",
              "distilbert-base-uncased         0.3496        79.7          99.0\n",
              "microsoft/deberta-base          0.3592       115.5         275.7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}