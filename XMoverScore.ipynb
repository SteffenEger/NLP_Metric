{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etwas\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"XMoverScore\")\n",
    "\n",
    "\n",
    "print(\"etwas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unbabel-comet\n",
      "  Using cached unbabel_comet-0.1.0-py3-none-any.whl (53 kB)\n",
      "Collecting scikit-learn==0.24\n",
      "  Using cached scikit_learn-0.24.0-cp38-cp38-win_amd64.whl (6.9 MB)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.0.0 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from unbabel-comet->-r requirements.txt (line 1)) (1.2.1)\n",
      "Collecting torch<=1.6\n",
      "  Using cached torch-0.1.2.post2.tar.gz (128 kB)\n",
      "Collecting sentencepiece==0.1.91\n",
      "  Using cached sentencepiece-0.1.91-cp38-cp38-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: numpy<1.20.0 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from unbabel-comet->-r requirements.txt (line 1)) (1.19.4)\n",
      "Collecting pytorch-lightning<=1.3\n",
      "  Using cached pytorch_lightning-1.3.0-py3-none-any.whl (804 kB)\n",
      "Collecting tensorboard==2.2.0\n",
      "  Using cached tensorboard-2.2.0-py3-none-any.whl (2.8 MB)\n",
      "Collecting transformers<5.0.0,>=4.0.0\n",
      "  Using cached transformers-4.6.1-py3-none-any.whl (2.2 MB)\n",
      "Collecting pytorch-nlp==0.5.0\n",
      "  Using cached pytorch_nlp-0.5.0-py3-none-any.whl (90 kB)\n",
      "Collecting fsspec==0.8.7\n",
      "  Using cached fsspec-0.8.7-py3-none-any.whl (103 kB)\n",
      "Requirement already satisfied: scipy<1.6.0,>=1.5.0 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from unbabel-comet->-r requirements.txt (line 1)) (1.5.4)\n",
      "Collecting fairseq==0.9.0\n",
      "  Using cached fairseq-0.9.0.tar.gz (306 kB)\n",
      "Requirement already satisfied: PyYAML<5.4.0,>=5.3.0 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from unbabel-comet->-r requirements.txt (line 1)) (5.3.1)\n",
      "Requirement already satisfied: cffi in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from fairseq==0.9.0->unbabel-comet->-r requirements.txt (line 1)) (1.14.4)\n",
      "Collecting cython\n",
      "  Using cached Cython-0.29.23-cp38-cp38-win_amd64.whl (1.7 MB)\n",
      "Requirement already satisfied: regex in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from fairseq==0.9.0->unbabel-comet->-r requirements.txt (line 1)) (2021.4.4)\n",
      "Collecting sacrebleu\n",
      "  Using cached sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: tqdm in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from fairseq==0.9.0->unbabel-comet->-r requirements.txt (line 1)) (4.60.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from scikit-learn==0.24->unbabel-comet->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from scikit-learn==0.24->unbabel-comet->-r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (0.12.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (2.25.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (0.4.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (1.30.0)\n",
      "Requirement already satisfied: wheel>=0.26 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (0.36.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (56.2.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (1.34.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (3.3.4)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (3.17.0)\n",
      "Requirement already satisfied: six>=1.10.0 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from pandas<2.0.0,>=1.0.0->unbabel-comet->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from pandas<2.0.0,>=1.0.0->unbabel-comet->-r requirements.txt (line 1)) (2021.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (0.4.8)\n",
      "Collecting fsspec[http]>=2021.4.0\n",
      "  Using cached fsspec-2021.6.0-py3-none-any.whl (114 kB)\n",
      "Requirement already satisfied: packaging in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from pytorch-lightning<=1.3->unbabel-comet->-r requirements.txt (line 1)) (20.9)\n",
      "Collecting torchmetrics>=0.2.0\n",
      "  Using cached torchmetrics-0.3.2-py3-none-any.whl (274 kB)\n",
      "Collecting pyDeprecate==0.3.0\n",
      "  Using cached pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting future>=0.17.1\n",
      "  Using cached future-0.18.2.tar.gz (829 kB)\n",
      "Collecting pytorch-lightning<=1.3\n",
      "  Using cached pytorch_lightning-1.2.10-py3-none-any.whl (841 kB)\n",
      "  Using cached pytorch_lightning-1.2.9-py3-none-any.whl (841 kB)\n",
      "  Using cached pytorch_lightning-1.2.8-py3-none-any.whl (841 kB)\n",
      "  Using cached pytorch_lightning-1.2.7-py3-none-any.whl (830 kB)\n",
      "  Using cached pytorch_lightning-1.2.6-py3-none-any.whl (829 kB)\n",
      "  Using cached pytorch_lightning-1.2.5-py3-none-any.whl (826 kB)\n",
      "  Using cached pytorch_lightning-1.2.4-py3-none-any.whl (829 kB)\n",
      "  Using cached pytorch_lightning-1.2.3-py3-none-any.whl (821 kB)\n",
      "  Using cached pytorch_lightning-1.2.2-py3-none-any.whl (816 kB)\n",
      "  Using cached pytorch_lightning-1.2.1-py3-none-any.whl (814 kB)\n",
      "  Using cached pytorch_lightning-1.2.0-py3-none-any.whl (813 kB)\n",
      "  Using cached pytorch_lightning-1.1.8-py3-none-any.whl (696 kB)\n",
      "  Using cached pytorch_lightning-1.1.7-py3-none-any.whl (695 kB)\n",
      "  Using cached pytorch_lightning-1.1.6-py3-none-any.whl (687 kB)\n",
      "  Using cached pytorch_lightning-1.1.5-py3-none-any.whl (685 kB)\n",
      "  Using cached pytorch_lightning-1.1.4-py3-none-any.whl (684 kB)\n",
      "  Using cached pytorch_lightning-1.1.3-py3-none-any.whl (680 kB)\n",
      "  Using cached pytorch_lightning-1.1.2-py3-none-any.whl (671 kB)\n",
      "  Using cached pytorch_lightning-1.1.1-py3-none-any.whl (669 kB)\n",
      "  Using cached pytorch_lightning-1.1.0-py3-none-any.whl (665 kB)\n",
      "  Using cached pytorch_lightning-1.0.8-py3-none-any.whl (561 kB)\n",
      "  Using cached pytorch_lightning-1.0.7-py3-none-any.whl (557 kB)\n",
      "  Using cached pytorch_lightning-1.0.6-py3-none-any.whl (548 kB)\n",
      "  Using cached pytorch_lightning-1.0.5-py3-none-any.whl (559 kB)\n",
      "  Using cached pytorch_lightning-1.0.4-py3-none-any.whl (554 kB)\n",
      "  Using cached pytorch_lightning-1.0.3-py3-none-any.whl (533 kB)\n",
      "  Using cached pytorch_lightning-1.0.2-py3-none-any.whl (532 kB)\n",
      "  Using cached pytorch_lightning-1.0.1-py3-none-any.whl (511 kB)\n",
      "  Using cached pytorch_lightning-1.0.0-py3-none-any.whl (510 kB)\n",
      "  Using cached pytorch_lightning-0.10.0-py3-none-any.whl (471 kB)\n",
      "  Using cached pytorch_lightning-0.9.0-py3-none-any.whl (408 kB)\n",
      "  Using cached pytorch_lightning-0.8.5-py3-none-any.whl (313 kB)\n",
      "  Using cached pytorch_lightning-0.8.4-py3-none-any.whl (304 kB)\n",
      "  Using cached pytorch_lightning-0.8.3-py3-none-any.whl (302 kB)\n",
      "  Using cached pytorch_lightning-0.8.1-py3-none-any.whl (293 kB)\n",
      "  Using cached pytorch_lightning-0.7.6-py3-none-any.whl (248 kB)\n",
      "  Using cached pytorch_lightning-0.7.5-py3-none-any.whl (233 kB)\n",
      "  Using cached pytorch_lightning-0.7.3-py3-none-any.whl (203 kB)\n",
      "  Using cached pytorch-lightning-0.7.1.tar.gz (6.0 MB)\n",
      "  Using cached pytorch-lightning-0.6.0.tar.gz (95 kB)\n",
      "  Using cached pytorch-lightning-0.5.3.3.tar.gz (95 kB)\n",
      "  Using cached pytorch-lightning-0.5.3.2.tar.gz (65 kB)\n",
      "  Using cached pytorch-lightning-0.5.3.1.tar.gz (55 kB)\n",
      "  Using cached pytorch-lightning-0.5.3.tar.gz (55 kB)\n",
      "  Using cached pytorch-lightning-0.5.2.1.tar.gz (56 kB)\n",
      "  Using cached pytorch-lightning-0.5.2.tar.gz (56 kB)\n",
      "  Using cached pytorch-lightning-0.5.1.3.tar.gz (55 kB)\n",
      "  Using cached pytorch-lightning-0.5.1.2.tar.gz (55 kB)\n",
      "  Using cached pytorch-lightning-0.5.1.tar.gz (55 kB)\n",
      "  Using cached pytorch-lightning-0.5.0.tar.gz (55 kB)\n",
      "  Using cached pytorch-lightning-0.4.9.tar.gz (55 kB)\n",
      "  Using cached pytorch-lightning-0.4.8.tar.gz (50 kB)\n",
      "  Using cached pytorch-lightning-0.4.7.tar.gz (51 kB)\n",
      "  Using cached pytorch-lightning-0.4.6.tar.gz (50 kB)\n",
      "  Using cached pytorch-lightning-0.4.5.tar.gz (47 kB)\n",
      "  Using cached pytorch-lightning-0.4.4.tar.gz (47 kB)\n",
      "  Using cached pytorch-lightning-0.4.3.tar.gz (44 kB)\n",
      "  Using cached pytorch-lightning-0.4.2.tar.gz (45 kB)\n",
      "  Using cached pytorch-lightning-0.4.1.tar.gz (45 kB)\n",
      "  Using cached pytorch-lightning-0.4.0.tar.gz (44 kB)\n",
      "  Using cached pytorch-lightning-0.3.6.9.tar.gz (369 kB)\n",
      "  Using cached pytorch-lightning-0.3.6.8.tar.gz (369 kB)\n",
      "  Using cached pytorch-lightning-0.3.6.7.tar.gz (369 kB)\n",
      "  Using cached pytorch-lightning-0.3.6.6.tar.gz (369 kB)\n",
      "  Using cached pytorch-lightning-0.3.6.5.tar.gz (369 kB)\n",
      "  Using cached pytorch-lightning-0.3.6.4.tar.gz (369 kB)\n",
      "  Using cached pytorch-lightning-0.3.6.3.tar.gz (369 kB)\n",
      "  Using cached pytorch-lightning-0.3.6.1.tar.gz (370 kB)\n",
      "  Using cached pytorch-lightning-0.3.6.tar.gz (369 kB)\n",
      "  Using cached pytorch-lightning-0.3.5.tar.gz (368 kB)\n",
      "  Using cached pytorch-lightning-0.3.4.1.tar.gz (359 kB)\n",
      "  Using cached pytorch-lightning-0.3.4.tar.gz (359 kB)\n",
      "  Using cached pytorch-lightning-0.3.3.tar.gz (359 kB)\n",
      "  Using cached pytorch-lightning-0.3.2.tar.gz (359 kB)\n",
      "  Using cached pytorch-lightning-0.3.1.tar.gz (358 kB)\n",
      "  Using cached pytorch-lightning-0.3.tar.gz (357 kB)\n",
      "  Using cached pytorch-lightning-0.2.6.tar.gz (357 kB)\n",
      "  Using cached pytorch-lightning-0.2.5.2.tar.gz (357 kB)\n",
      "  Using cached pytorch-lightning-0.2.5.1.tar.gz (357 kB)\n",
      "  Using cached pytorch-lightning-0.2.5.tar.gz (357 kB)\n",
      "  Using cached pytorch-lightning-0.2.4.1.tar.gz (356 kB)\n",
      "  Using cached pytorch-lightning-0.2.4.tar.gz (356 kB)\n",
      "  Using cached pytorch-lightning-0.2.3.tar.gz (356 kB)\n",
      "  Using cached pytorch-lightning-0.2.2.tar.gz (356 kB)\n",
      "  Using cached pytorch-lightning-0.2.tar.gz (356 kB)\n",
      "  Using cached pytorch_lightning-0.0.2-py3-none-any.whl\n",
      "Collecting test-tube\n",
      "  Using cached test_tube-0.7.5.tar.gz (21 kB)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (2020.11.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (1.26.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.2.0->unbabel-comet->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: sacremoses in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from transformers<5.0.0,>=4.0.0->unbabel-comet->-r requirements.txt (line 1)) (0.0.45)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from transformers<5.0.0,>=4.0.0->unbabel-comet->-r requirements.txt (line 1)) (0.0.8)\n",
      "Requirement already satisfied: filelock in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from transformers<5.0.0,>=4.0.0->unbabel-comet->-r requirements.txt (line 1)) (3.0.12)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Using cached tokenizers-0.10.3-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: pycparser in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from cffi->fairseq==0.9.0->unbabel-comet->-r requirements.txt (line 1)) (2.20)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from packaging->pytorch-lightning<=1.3->unbabel-comet->-r requirements.txt (line 1)) (2.4.7)\n",
      "Requirement already satisfied: portalocker==2.0.0 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from sacrebleu->fairseq==0.9.0->unbabel-comet->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: pywin32!=226 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from portalocker==2.0.0->sacrebleu->fairseq==0.9.0->unbabel-comet->-r requirements.txt (line 1)) (300)\n",
      "Requirement already satisfied: click in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from sacremoses->transformers<5.0.0,>=4.0.0->unbabel-comet->-r requirements.txt (line 1)) (7.0)\n",
      "Collecting imageio>=2.3.0\n",
      "  Using cached imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "Collecting test-tube\n",
      "  Using cached test_tube-0.7.4.tar.gz (21 kB)\n",
      "  Using cached test_tube-0.7.3.tar.gz (21 kB)\n",
      "Collecting tb-nightly==1.15.0a20190708\n",
      "  Using cached tb_nightly-1.15.0a20190708-py3-none-any.whl (3.9 MB)\n",
      "Collecting test-tube\n",
      "  Using cached test_tube-0.7.2.tar.gz (21 kB)\n",
      "  Using cached test_tube-0.7.1.tar.gz (20 kB)\n",
      "  Using cached test_tube-0.7.0.tar.gz (20 kB)\n",
      "  Using cached test_tube-0.6.9.tar.gz (20 kB)\n",
      "  Using cached test_tube-0.6.8.tar.gz (20 kB)\n",
      "  Using cached test_tube-0.6.7.6.tar.gz (21 kB)\n",
      "  Using cached test_tube-0.6.7.5.tar.gz (21 kB)\n",
      "  Using cached test_tube-0.6.7.4.tar.gz (20 kB)\n",
      "  Using cached test_tube-0.6.7.3.tar.gz (20 kB)\n",
      "  Using cached test_tube-0.6.7.2.tar.gz (20 kB)\n",
      "  Using cached test_tube-0.6.7.1.tar.gz (20 kB)\n",
      "  Using cached test_tube-0.6.7.tar.gz (20 kB)\n",
      "  Using cached test_tube-0.6.6.tar.gz (20 kB)\n",
      "  Using cached test_tube-0.2-py3-none-any.whl\n",
      "Building wheels for collected packages: fairseq, torch\n",
      "  Building wheel for fairseq (setup.py): started\n",
      "  Building wheel for fairseq (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for fairseq\n",
      "  Building wheel for torch (setup.py): started\n",
      "  Building wheel for torch (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for torch\n",
      "Failed to build fairseq torch\n",
      "Installing collected packages: torch, tokenizers, test-tube, sacrebleu, cython, transformers, tensorboard, sentencepiece, scikit-learn, pytorch-nlp, pytorch-lightning, fsspec, fairseq, unbabel-comet\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.8.1\n",
      "    Uninstalling torch-1.8.1:\n",
      "      Successfully uninstalled torch-1.8.1\n",
      "    Running setup.py install for torch: started\n",
      "    Running setup.py install for torch: finished with status 'error'\n",
      "  Rolling back uninstall of torch\n",
      "  Moving to e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages\\caffe2\\\n",
      "   from E:\\Pyhton_Verzeichnis\\Bib_Daten\\Lib\\site-packages\\~affe2\n",
      "  Moving to e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages\\torch-1.8.1.dist-info\\\n",
      "   from E:\\Pyhton_Verzeichnis\\Bib_Daten\\Lib\\site-packages\\~orch-1.8.1.dist-info\n",
      "  Moving to e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages\\torch\\\n",
      "   from E:\\Pyhton_Verzeichnis\\Bib_Daten\\Lib\\site-packages\\~orch\n",
      "  Moving to e:\\pyhton_verzeichnis\\bib_daten\\scripts\\convert-caffe2-to-onnx.exe\n",
      "   from C:\\Users\\stari\\AppData\\Local\\Temp\\pip-uninstall-g5ba1eyo\\convert-caffe2-to-onnx.exe\n",
      "  Moving to e:\\pyhton_verzeichnis\\bib_daten\\scripts\\convert-onnx-to-caffe2.exe\n",
      "   from C:\\Users\\stari\\AppData\\Local\\Temp\\pip-uninstall-g5ba1eyo\\convert-onnx-to-caffe2.exe\n",
      "Requirement already satisfied: transformers in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: tokenizers==0.5.2 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: sacremoses in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: sentencepiece in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from transformers) (0.1.95)\n",
      "Requirement already satisfied: requests in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from transformers) (2.25.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from transformers) (4.60.0)\n",
      "Requirement already satisfied: numpy in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from transformers) (1.19.4)\n",
      "Requirement already satisfied: filelock in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: boto3 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from transformers) (1.17.73)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from boto3->transformers) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from boto3->transformers) (0.4.2)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.73 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from boto3->transformers) (1.20.73)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from botocore<1.21.0,>=1.20.73->boto3->transformers) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from botocore<1.21.0,>=1.20.73->boto3->transformers) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.73->boto3->transformers) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from requests->transformers) (2020.11.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: click in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: truecase in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (0.0.12)\n",
      "Requirement already satisfied: nltk in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from truecase) (3.4)\n",
      "Requirement already satisfied: singledispatch in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from nltk->truecase) (3.6.1)\n",
      "Requirement already satisfied: six in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from nltk->truecase) (1.15.0)\n",
      "Requirement already satisfied: mosestokenizer in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: toolwrapper in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from mosestokenizer) (2.1.0)\n",
      "Requirement already satisfied: openfile in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from mosestokenizer) (0.0.7)\n",
      "Requirement already satisfied: docopt in e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages (from mosestokenizer) (0.6.2)\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'e:\\pyhton_verzeichnis\\bib_daten\\python.exe' -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\stari\\\\AppData\\\\Local\\\\Temp\\\\pip-install-seaubbjf\\\\test-tube_ca3a1159dd48409fb45929843c9aca54\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\stari\\\\AppData\\\\Local\\\\Temp\\\\pip-install-seaubbjf\\\\test-tube_ca3a1159dd48409fb45929843c9aca54\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base 'C:\\Users\\stari\\AppData\\Local\\Temp\\pip-pip-egg-info-d1867ogv'\n",
      "         cwd: C:\\Users\\stari\\AppData\\Local\\Temp\\pip-install-seaubbjf\\test-tube_ca3a1159dd48409fb45929843c9aca54\\\n",
      "    Complete output (7 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\stari\\AppData\\Local\\Temp\\pip-install-seaubbjf\\test-tube_ca3a1159dd48409fb45929843c9aca54\\setup.py\", line 28, in <module>\n",
      "        install_requires=load_requirements(PATH_ROOT),\n",
      "      File \"C:\\Users\\stari\\AppData\\Local\\Temp\\pip-install-seaubbjf\\test-tube_ca3a1159dd48409fb45929843c9aca54\\setup.py\", line 10, in load_requirements\n",
      "        with open(os.path.join(path_dir, 'requirements.txt'), 'r') as file:\n",
      "    FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\stari\\\\AppData\\\\Local\\\\Temp\\\\pip-install-seaubbjf\\\\test-tube_ca3a1159dd48409fb45929843c9aca54\\\\requirements.txt'\n",
      "    ----------------------------------------\n",
      "WARNING: Discarding https://files.pythonhosted.org/packages/dc/7a/38570026d3a58684348b7db8853c9c1a62f05e5ec6610716b8e92216e1bc/test_tube-0.7.4.tar.gz#sha256=0a827bd847eea6b7fbcd6bd80b2f7494fbe68d91d28280335dd26bd0c41e26ed (from https://pypi.org/simple/test-tube/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\n",
      "WARNING: The candidate selected for download or install is a yanked version: 'torch' candidate (version 0.1.2.post2 at https://files.pythonhosted.org/packages/f8/02/880b468bd382dc79896eaecbeb8ce95e9c4b99a24902874a2cef0b562cea/torch-0.1.2.post2.tar.gz#sha256=a43e37f8f927c5b18f80cd163daaf6a1920edafcab5102e02e3e14bb97d9c874 (from https://pypi.org/simple/torch/))\n",
      "Reason for being yanked: 0.1.2 is past it's support date and confuses users on unsupported platforms\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'e:\\pyhton_verzeichnis\\bib_daten\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\stari\\\\AppData\\\\Local\\\\Temp\\\\pip-install-seaubbjf\\\\fairseq_ea4e5db96a9b42439873b0474892cdc8\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\stari\\\\AppData\\\\Local\\\\Temp\\\\pip-install-seaubbjf\\\\fairseq_ea4e5db96a9b42439873b0474892cdc8\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\stari\\AppData\\Local\\Temp\\pip-wheel-ee64hrrb'\n",
      "       cwd: C:\\Users\\stari\\AppData\\Local\\Temp\\pip-install-seaubbjf\\fairseq_ea4e5db96a9b42439873b0474892cdc8\\\n",
      "  Complete output (274 lines):\n",
      "  running bdist_wheel\n",
      "  e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages\\torch\\utils\\cpp_extension.py:369: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "    warnings.warn(msg.format('we could not find ninja.'))\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.8\n",
      "  creating build\\lib.win-amd64-3.8\\examples\n",
      "  copying examples\\__init__.py -> build\\lib.win-amd64-3.8\\examples\n",
      "  creating build\\lib.win-amd64-3.8\\fairseq\n",
      "  copying fairseq\\binarizer.py -> build\\lib.win-amd64-3.8\\fairseq\n",
      "  copying fairseq\\bleu.py -> build\\lib.win-amd64-3.8\\fairseq\n",
      "  copying fairseq\\checkpoint_utils.py -> build\\lib.win-amd64-3.8\\fairseq\n",
      "  copying fairseq\\distributed_utils.py -> build\\lib.win-amd64-3.8\\fairseq\n",
      "  copying fairseq\\file_utils.py -> build\\lib.win-amd64-3.8\\fairseq\n",
      "  copying fairseq\\hub_utils.py -> build\\lib.win-amd64-3.8\\fairseq\n",
      "  copying fairseq\\iterative_refinement_generator.py -> build\\lib.win-amd64-3.8\\fairseq\n",
      "  copying fairseq\\legacy_distributed_data_parallel.py -> build\\lib.win-amd64-3.8\\fairseq\n",
      "  copying fairseq\\meters.py -> build\\lib.win-amd64-3.8\\fairseq\n",
      "  copying fairseq\\options.py -> build\\lib.win-amd64-3.8\\fairseq\n",
      "  copying fairseq\\pdb.py -> build\\lib.win-amd64-3.8\\fairseq\n",
      "  copying fairseq\\progress_bar.py -> build\\lib.win-amd64-3.8\\fairseq\n",
      "  copying fairseq\\registry.py -> build\\lib.win-amd64-3.8\\fairseq\n",
      "  copying fairseq\\search.py -> build\\lib.win-amd64-3.8\\fairseq\n",
      "  copying fairseq\\sequence_generator.py -> build\\lib.win-amd64-3.8\\fairseq\n",
      "  copying fairseq\\sequence_scorer.py -> build\\lib.win-amd64-3.8\\fairseq\n",
      "  copying fairseq\\tokenizer.py -> build\\lib.win-amd64-3.8\\fairseq\n",
      "  copying fairseq\\trainer.py -> build\\lib.win-amd64-3.8\\fairseq\n",
      "  copying fairseq\\utils.py -> build\\lib.win-amd64-3.8\\fairseq\n",
      "  copying fairseq\\__init__.py -> build\\lib.win-amd64-3.8\\fairseq\n",
      "  creating build\\lib.win-amd64-3.8\\fairseq_cli\n",
      "  copying fairseq_cli\\eval_lm.py -> build\\lib.win-amd64-3.8\\fairseq_cli\n",
      "  copying fairseq_cli\\generate.py -> build\\lib.win-amd64-3.8\\fairseq_cli\n",
      "  copying fairseq_cli\\interactive.py -> build\\lib.win-amd64-3.8\\fairseq_cli\n",
      "  copying fairseq_cli\\preprocess.py -> build\\lib.win-amd64-3.8\\fairseq_cli\n",
      "  copying fairseq_cli\\score.py -> build\\lib.win-amd64-3.8\\fairseq_cli\n",
      "  copying fairseq_cli\\setup.py -> build\\lib.win-amd64-3.8\\fairseq_cli\n",
      "  copying fairseq_cli\\train.py -> build\\lib.win-amd64-3.8\\fairseq_cli\n",
      "  copying fairseq_cli\\__init__.py -> build\\lib.win-amd64-3.8\\fairseq_cli\n",
      "  creating build\\lib.win-amd64-3.8\\examples\\noisychannel\n",
      "  copying examples\\noisychannel\\rerank.py -> build\\lib.win-amd64-3.8\\examples\\noisychannel\n",
      "  copying examples\\noisychannel\\rerank_generate.py -> build\\lib.win-amd64-3.8\\examples\\noisychannel\n",
      "  copying examples\\noisychannel\\rerank_options.py -> build\\lib.win-amd64-3.8\\examples\\noisychannel\n",
      "  copying examples\\noisychannel\\rerank_score_bw.py -> build\\lib.win-amd64-3.8\\examples\\noisychannel\n",
      "  copying examples\\noisychannel\\rerank_score_lm.py -> build\\lib.win-amd64-3.8\\examples\\noisychannel\n",
      "  copying examples\\noisychannel\\rerank_tune.py -> build\\lib.win-amd64-3.8\\examples\\noisychannel\n",
      "  copying examples\\noisychannel\\rerank_utils.py -> build\\lib.win-amd64-3.8\\examples\\noisychannel\n",
      "  copying examples\\noisychannel\\__init__.py -> build\\lib.win-amd64-3.8\\examples\\noisychannel\n",
      "  creating build\\lib.win-amd64-3.8\\examples\\speech_recognition\n",
      "  copying examples\\speech_recognition\\infer.py -> build\\lib.win-amd64-3.8\\examples\\speech_recognition\n",
      "  copying examples\\speech_recognition\\w2l_decoder.py -> build\\lib.win-amd64-3.8\\examples\\speech_recognition\n",
      "  copying examples\\speech_recognition\\__init__.py -> build\\lib.win-amd64-3.8\\examples\\speech_recognition\n",
      "  creating build\\lib.win-amd64-3.8\\examples\\speech_recognition\\criterions\n",
      "  copying examples\\speech_recognition\\criterions\\ASG_loss.py -> build\\lib.win-amd64-3.8\\examples\\speech_recognition\\criterions\n",
      "  copying examples\\speech_recognition\\criterions\\cross_entropy_acc.py -> build\\lib.win-amd64-3.8\\examples\\speech_recognition\\criterions\n",
      "  copying examples\\speech_recognition\\criterions\\CTC_loss.py -> build\\lib.win-amd64-3.8\\examples\\speech_recognition\\criterions\n",
      "  copying examples\\speech_recognition\\criterions\\__init__.py -> build\\lib.win-amd64-3.8\\examples\\speech_recognition\\criterions\n",
      "  creating build\\lib.win-amd64-3.8\\examples\\speech_recognition\\data\n",
      "  copying examples\\speech_recognition\\data\\asr_dataset.py -> build\\lib.win-amd64-3.8\\examples\\speech_recognition\\data\n",
      "  copying examples\\speech_recognition\\data\\collaters.py -> build\\lib.win-amd64-3.8\\examples\\speech_recognition\\data\n",
      "  copying examples\\speech_recognition\\data\\data_utils.py -> build\\lib.win-amd64-3.8\\examples\\speech_recognition\\data\n",
      "  copying examples\\speech_recognition\\data\\replabels.py -> build\\lib.win-amd64-3.8\\examples\\speech_recognition\\data\n",
      "  copying examples\\speech_recognition\\data\\__init__.py -> build\\lib.win-amd64-3.8\\examples\\speech_recognition\\data\n",
      "  creating build\\lib.win-amd64-3.8\\examples\\speech_recognition\\models\n",
      "  copying examples\\speech_recognition\\models\\vggtransformer.py -> build\\lib.win-amd64-3.8\\examples\\speech_recognition\\models\n",
      "  copying examples\\speech_recognition\\models\\w2l_conv_glu_enc.py -> build\\lib.win-amd64-3.8\\examples\\speech_recognition\\models\n",
      "  copying examples\\speech_recognition\\models\\__init__.py -> build\\lib.win-amd64-3.8\\examples\\speech_recognition\\models\n",
      "  creating build\\lib.win-amd64-3.8\\examples\\speech_recognition\\tasks\n",
      "  copying examples\\speech_recognition\\tasks\\speech_recognition.py -> build\\lib.win-amd64-3.8\\examples\\speech_recognition\\tasks\n",
      "  copying examples\\speech_recognition\\tasks\\__init__.py -> build\\lib.win-amd64-3.8\\examples\\speech_recognition\\tasks\n",
      "  creating build\\lib.win-amd64-3.8\\fairseq\\criterions\n",
      "  copying fairseq\\criterions\\adaptive_loss.py -> build\\lib.win-amd64-3.8\\fairseq\\criterions\n",
      "  copying fairseq\\criterions\\binary_cross_entropy.py -> build\\lib.win-amd64-3.8\\fairseq\\criterions\n",
      "  copying fairseq\\criterions\\composite_loss.py -> build\\lib.win-amd64-3.8\\fairseq\\criterions\n",
      "  copying fairseq\\criterions\\cross_entropy.py -> build\\lib.win-amd64-3.8\\fairseq\\criterions\n",
      "  copying fairseq\\criterions\\fairseq_criterion.py -> build\\lib.win-amd64-3.8\\fairseq\\criterions\n",
      "  copying fairseq\\criterions\\label_smoothed_cross_entropy.py -> build\\lib.win-amd64-3.8\\fairseq\\criterions\n",
      "  copying fairseq\\criterions\\label_smoothed_cross_entropy_with_alignment.py -> build\\lib.win-amd64-3.8\\fairseq\\criterions\n",
      "  copying fairseq\\criterions\\legacy_masked_lm.py -> build\\lib.win-amd64-3.8\\fairseq\\criterions\n",
      "  copying fairseq\\criterions\\masked_lm.py -> build\\lib.win-amd64-3.8\\fairseq\\criterions\n",
      "  copying fairseq\\criterions\\nat_loss.py -> build\\lib.win-amd64-3.8\\fairseq\\criterions\n",
      "  copying fairseq\\criterions\\sentence_prediction.py -> build\\lib.win-amd64-3.8\\fairseq\\criterions\n",
      "  copying fairseq\\criterions\\sentence_ranking.py -> build\\lib.win-amd64-3.8\\fairseq\\criterions\n",
      "  copying fairseq\\criterions\\__init__.py -> build\\lib.win-amd64-3.8\\fairseq\\criterions\n",
      "  creating build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\append_token_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\backtranslation_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\base_wrapper_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\colorize_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\concat_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\concat_sentences_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\data_utils.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\denoising_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\dictionary.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\fairseq_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\id_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\indexed_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\iterators.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\language_pair_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\list_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\lm_context_window_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\lru_cache_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\mask_tokens_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\monolingual_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\multi_corpus_sampled_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\nested_dictionary_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\noising.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\numel_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\num_samples_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\offset_tokens_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\pad_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\plasma_utils.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\prepend_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\prepend_token_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\raw_label_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\replace_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\resampling_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\roll_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\round_robin_zip_datasets.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\sharded_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\sort_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\strip_token_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\subsample_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\token_block_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\transform_eos_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\transform_eos_lang_pair_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\truncate_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  copying fairseq\\data\\__init__.py -> build\\lib.win-amd64-3.8\\fairseq\\data\n",
      "  creating build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\cmlm_transformer.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\composite_encoder.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\distributed_fairseq_model.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\fairseq_decoder.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\fairseq_encoder.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\fairseq_incremental_decoder.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\fairseq_model.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\fconv.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\fconv_lm.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\fconv_self_att.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\insertion_transformer.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\iterative_nonautoregressive_transformer.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\levenshtein_transformer.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\lightconv.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\lightconv_lm.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\lstm.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\masked_lm.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\model_utils.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\multilingual_transformer.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\nonautoregressive_ensembles.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\nonautoregressive_transformer.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\transformer.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\transformer_from_pretrained_xlm.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\transformer_lm.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\wav2vec.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  copying fairseq\\models\\__init__.py -> build\\lib.win-amd64-3.8\\fairseq\\models\n",
      "  creating build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\adaptive_input.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\adaptive_softmax.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\beamable_mm.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\character_token_embedder.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\conv_tbc.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\downsampled_multihead_attention.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\dynamic_convolution.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\gelu.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\grad_multiply.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\highway.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\layer_norm.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\learned_positional_embedding.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\lightweight_convolution.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\linearized_convolution.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\logsumexp_moe.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\mean_pool_gating_network.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\multihead_attention.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\positional_embedding.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\scalar_bias.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\sinusoidal_positional_embedding.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\sparse_multihead_attention.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\sparse_transformer_sentence_encoder.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\sparse_transformer_sentence_encoder_layer.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\transformer_layer.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\transformer_sentence_encoder.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\transformer_sentence_encoder_layer.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\unfold.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\vggblock.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  copying fairseq\\modules\\__init__.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\n",
      "  creating build\\lib.win-amd64-3.8\\fairseq\\optim\n",
      "  copying fairseq\\optim\\adadelta.py -> build\\lib.win-amd64-3.8\\fairseq\\optim\n",
      "  copying fairseq\\optim\\adafactor.py -> build\\lib.win-amd64-3.8\\fairseq\\optim\n",
      "  copying fairseq\\optim\\adagrad.py -> build\\lib.win-amd64-3.8\\fairseq\\optim\n",
      "  copying fairseq\\optim\\adam.py -> build\\lib.win-amd64-3.8\\fairseq\\optim\n",
      "  copying fairseq\\optim\\adamax.py -> build\\lib.win-amd64-3.8\\fairseq\\optim\n",
      "  copying fairseq\\optim\\bmuf.py -> build\\lib.win-amd64-3.8\\fairseq\\optim\n",
      "  copying fairseq\\optim\\fairseq_optimizer.py -> build\\lib.win-amd64-3.8\\fairseq\\optim\n",
      "  copying fairseq\\optim\\fp16_optimizer.py -> build\\lib.win-amd64-3.8\\fairseq\\optim\n",
      "  copying fairseq\\optim\\nag.py -> build\\lib.win-amd64-3.8\\fairseq\\optim\n",
      "  copying fairseq\\optim\\sgd.py -> build\\lib.win-amd64-3.8\\fairseq\\optim\n",
      "  copying fairseq\\optim\\__init__.py -> build\\lib.win-amd64-3.8\\fairseq\\optim\n",
      "  creating build\\lib.win-amd64-3.8\\fairseq\\tasks\n",
      "  copying fairseq\\tasks\\audio_pretraining.py -> build\\lib.win-amd64-3.8\\fairseq\\tasks\n",
      "  copying fairseq\\tasks\\cross_lingual_lm.py -> build\\lib.win-amd64-3.8\\fairseq\\tasks\n",
      "  copying fairseq\\tasks\\denoising.py -> build\\lib.win-amd64-3.8\\fairseq\\tasks\n",
      "  copying fairseq\\tasks\\fairseq_task.py -> build\\lib.win-amd64-3.8\\fairseq\\tasks\n",
      "  copying fairseq\\tasks\\language_modeling.py -> build\\lib.win-amd64-3.8\\fairseq\\tasks\n",
      "  copying fairseq\\tasks\\legacy_masked_lm.py -> build\\lib.win-amd64-3.8\\fairseq\\tasks\n",
      "  copying fairseq\\tasks\\masked_lm.py -> build\\lib.win-amd64-3.8\\fairseq\\tasks\n",
      "  copying fairseq\\tasks\\multilingual_masked_lm.py -> build\\lib.win-amd64-3.8\\fairseq\\tasks\n",
      "  copying fairseq\\tasks\\multilingual_translation.py -> build\\lib.win-amd64-3.8\\fairseq\\tasks\n",
      "  copying fairseq\\tasks\\semisupervised_translation.py -> build\\lib.win-amd64-3.8\\fairseq\\tasks\n",
      "  copying fairseq\\tasks\\sentence_prediction.py -> build\\lib.win-amd64-3.8\\fairseq\\tasks\n",
      "  copying fairseq\\tasks\\sentence_ranking.py -> build\\lib.win-amd64-3.8\\fairseq\\tasks\n",
      "  copying fairseq\\tasks\\translation.py -> build\\lib.win-amd64-3.8\\fairseq\\tasks\n",
      "  copying fairseq\\tasks\\translation_from_pretrained_xlm.py -> build\\lib.win-amd64-3.8\\fairseq\\tasks\n",
      "  copying fairseq\\tasks\\translation_lev.py -> build\\lib.win-amd64-3.8\\fairseq\\tasks\n",
      "  copying fairseq\\tasks\\translation_moe.py -> build\\lib.win-amd64-3.8\\fairseq\\tasks\n",
      "  copying fairseq\\tasks\\__init__.py -> build\\lib.win-amd64-3.8\\fairseq\\tasks\n",
      "  creating build\\lib.win-amd64-3.8\\fairseq\\data\\audio\n",
      "  copying fairseq\\data\\audio\\raw_audio_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\\audio\n",
      "  copying fairseq\\data\\audio\\__init__.py -> build\\lib.win-amd64-3.8\\fairseq\\data\\audio\n",
      "  creating build\\lib.win-amd64-3.8\\fairseq\\data\\encoders\n",
      "  copying fairseq\\data\\encoders\\fastbpe.py -> build\\lib.win-amd64-3.8\\fairseq\\data\\encoders\n",
      "  copying fairseq\\data\\encoders\\gpt2_bpe.py -> build\\lib.win-amd64-3.8\\fairseq\\data\\encoders\n",
      "  copying fairseq\\data\\encoders\\gpt2_bpe_utils.py -> build\\lib.win-amd64-3.8\\fairseq\\data\\encoders\n",
      "  copying fairseq\\data\\encoders\\hf_bert_bpe.py -> build\\lib.win-amd64-3.8\\fairseq\\data\\encoders\n",
      "  copying fairseq\\data\\encoders\\moses_tokenizer.py -> build\\lib.win-amd64-3.8\\fairseq\\data\\encoders\n",
      "  copying fairseq\\data\\encoders\\nltk_tokenizer.py -> build\\lib.win-amd64-3.8\\fairseq\\data\\encoders\n",
      "  copying fairseq\\data\\encoders\\sentencepiece_bpe.py -> build\\lib.win-amd64-3.8\\fairseq\\data\\encoders\n",
      "  copying fairseq\\data\\encoders\\space_tokenizer.py -> build\\lib.win-amd64-3.8\\fairseq\\data\\encoders\n",
      "  copying fairseq\\data\\encoders\\subword_nmt_bpe.py -> build\\lib.win-amd64-3.8\\fairseq\\data\\encoders\n",
      "  copying fairseq\\data\\encoders\\utils.py -> build\\lib.win-amd64-3.8\\fairseq\\data\\encoders\n",
      "  copying fairseq\\data\\encoders\\__init__.py -> build\\lib.win-amd64-3.8\\fairseq\\data\\encoders\n",
      "  creating build\\lib.win-amd64-3.8\\fairseq\\data\\legacy\n",
      "  copying fairseq\\data\\legacy\\block_pair_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\\legacy\n",
      "  copying fairseq\\data\\legacy\\masked_lm_dataset.py -> build\\lib.win-amd64-3.8\\fairseq\\data\\legacy\n",
      "  copying fairseq\\data\\legacy\\masked_lm_dictionary.py -> build\\lib.win-amd64-3.8\\fairseq\\data\\legacy\n",
      "  copying fairseq\\data\\legacy\\__init__.py -> build\\lib.win-amd64-3.8\\fairseq\\data\\legacy\n",
      "  creating build\\lib.win-amd64-3.8\\fairseq\\models\\bart\n",
      "  copying fairseq\\models\\bart\\hub_interface.py -> build\\lib.win-amd64-3.8\\fairseq\\models\\bart\n",
      "  copying fairseq\\models\\bart\\model.py -> build\\lib.win-amd64-3.8\\fairseq\\models\\bart\n",
      "  copying fairseq\\models\\bart\\__init__.py -> build\\lib.win-amd64-3.8\\fairseq\\models\\bart\n",
      "  creating build\\lib.win-amd64-3.8\\fairseq\\models\\roberta\n",
      "  copying fairseq\\models\\roberta\\alignment_utils.py -> build\\lib.win-amd64-3.8\\fairseq\\models\\roberta\n",
      "  copying fairseq\\models\\roberta\\hub_interface.py -> build\\lib.win-amd64-3.8\\fairseq\\models\\roberta\n",
      "  copying fairseq\\models\\roberta\\model.py -> build\\lib.win-amd64-3.8\\fairseq\\models\\roberta\n",
      "  copying fairseq\\models\\roberta\\__init__.py -> build\\lib.win-amd64-3.8\\fairseq\\models\\roberta\n",
      "  creating build\\lib.win-amd64-3.8\\fairseq\\modules\\dynamicconv_layer\n",
      "  copying fairseq\\modules\\dynamicconv_layer\\cuda_function_gen.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\\dynamicconv_layer\n",
      "  copying fairseq\\modules\\dynamicconv_layer\\dynamicconv_layer.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\\dynamicconv_layer\n",
      "  copying fairseq\\modules\\dynamicconv_layer\\setup.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\\dynamicconv_layer\n",
      "  copying fairseq\\modules\\dynamicconv_layer\\__init__.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\\dynamicconv_layer\n",
      "  creating build\\lib.win-amd64-3.8\\fairseq\\modules\\lightconv_layer\n",
      "  copying fairseq\\modules\\lightconv_layer\\cuda_function_gen.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\\lightconv_layer\n",
      "  copying fairseq\\modules\\lightconv_layer\\lightconv_layer.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\\lightconv_layer\n",
      "  copying fairseq\\modules\\lightconv_layer\\setup.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\\lightconv_layer\n",
      "  copying fairseq\\modules\\lightconv_layer\\__init__.py -> build\\lib.win-amd64-3.8\\fairseq\\modules\\lightconv_layer\n",
      "  creating build\\lib.win-amd64-3.8\\fairseq\\optim\\lr_scheduler\n",
      "  copying fairseq\\optim\\lr_scheduler\\cosine_lr_scheduler.py -> build\\lib.win-amd64-3.8\\fairseq\\optim\\lr_scheduler\n",
      "  copying fairseq\\optim\\lr_scheduler\\fairseq_lr_scheduler.py -> build\\lib.win-amd64-3.8\\fairseq\\optim\\lr_scheduler\n",
      "  copying fairseq\\optim\\lr_scheduler\\fixed_schedule.py -> build\\lib.win-amd64-3.8\\fairseq\\optim\\lr_scheduler\n",
      "  copying fairseq\\optim\\lr_scheduler\\inverse_square_root_schedule.py -> build\\lib.win-amd64-3.8\\fairseq\\optim\\lr_scheduler\n",
      "  copying fairseq\\optim\\lr_scheduler\\polynomial_decay_schedule.py -> build\\lib.win-amd64-3.8\\fairseq\\optim\\lr_scheduler\n",
      "  copying fairseq\\optim\\lr_scheduler\\reduce_lr_on_plateau.py -> build\\lib.win-amd64-3.8\\fairseq\\optim\\lr_scheduler\n",
      "  copying fairseq\\optim\\lr_scheduler\\triangular_lr_scheduler.py -> build\\lib.win-amd64-3.8\\fairseq\\optim\\lr_scheduler\n",
      "  copying fairseq\\optim\\lr_scheduler\\tri_stage_lr_scheduler.py -> build\\lib.win-amd64-3.8\\fairseq\\optim\\lr_scheduler\n",
      "  copying fairseq\\optim\\lr_scheduler\\__init__.py -> build\\lib.win-amd64-3.8\\fairseq\\optim\\lr_scheduler\n",
      "  running build_ext\n",
      "  e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages\\torch\\utils\\cpp_extension.py:304: UserWarning: Error checking compiler version for cl: [WinError 2] Das System kann die angegebene Datei nicht finden\n",
      "    warnings.warn(f'Error checking compiler version for {compiler}: {error}')\n",
      "  building 'fairseq.libbleu' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  Error in atexit._run_exitfuncs:\n",
      "  Traceback (most recent call last):\n",
      "    File \"e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages\\colorama\\ansitowin32.py\", line 59, in closed\n",
      "      return stream.closed\n",
      "  ValueError: underlying buffer has been detached\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for fairseq\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'e:\\pyhton_verzeichnis\\bib_daten\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\stari\\\\AppData\\\\Local\\\\Temp\\\\pip-install-seaubbjf\\\\torch_03e97498a49148ca8134dae3646769f5\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\stari\\\\AppData\\\\Local\\\\Temp\\\\pip-install-seaubbjf\\\\torch_03e97498a49148ca8134dae3646769f5\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\stari\\AppData\\Local\\Temp\\pip-wheel-ipts1wm6'\n",
      "       cwd: C:\\Users\\stari\\AppData\\Local\\Temp\\pip-install-seaubbjf\\torch_03e97498a49148ca8134dae3646769f5\\\n",
      "  Complete output (30 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_deps\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"C:\\Users\\stari\\AppData\\Local\\Temp\\pip-install-seaubbjf\\torch_03e97498a49148ca8134dae3646769f5\\setup.py\", line 225, in <module>\n",
      "      setup(name=\"torch\", version=\"0.1.2.post2\",\n",
      "    File \"e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages\\setuptools\\__init__.py\", line 153, in setup\n",
      "      return distutils.core.setup(**attrs)\n",
      "    File \"e:\\pyhton_verzeichnis\\bib_daten\\lib\\distutils\\core.py\", line 148, in setup\n",
      "      dist.run_commands()\n",
      "    File \"e:\\pyhton_verzeichnis\\bib_daten\\lib\\distutils\\dist.py\", line 966, in run_commands\n",
      "      self.run_command(cmd)\n",
      "    File \"e:\\pyhton_verzeichnis\\bib_daten\\lib\\distutils\\dist.py\", line 985, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages\\wheel\\bdist_wheel.py\", line 299, in run\n",
      "      self.run_command('build')\n",
      "    File \"e:\\pyhton_verzeichnis\\bib_daten\\lib\\distutils\\cmd.py\", line 313, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"e:\\pyhton_verzeichnis\\bib_daten\\lib\\distutils\\dist.py\", line 985, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"e:\\pyhton_verzeichnis\\bib_daten\\lib\\distutils\\command\\build.py\", line 135, in run\n",
      "      self.run_command(cmd_name)\n",
      "    File \"e:\\pyhton_verzeichnis\\bib_daten\\lib\\distutils\\cmd.py\", line 313, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"e:\\pyhton_verzeichnis\\bib_daten\\lib\\distutils\\dist.py\", line 985, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\stari\\AppData\\Local\\Temp\\pip-install-seaubbjf\\torch_03e97498a49148ca8134dae3646769f5\\setup.py\", line 51, in run\n",
      "      from tools.nnwrap import generate_wrappers as generate_nn_wrappers\n",
      "  ModuleNotFoundError: No module named 'tools.nnwrap'\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for torch\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'e:\\pyhton_verzeichnis\\bib_daten\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\stari\\\\AppData\\\\Local\\\\Temp\\\\pip-install-seaubbjf\\\\torch_03e97498a49148ca8134dae3646769f5\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\stari\\\\AppData\\\\Local\\\\Temp\\\\pip-install-seaubbjf\\\\torch_03e97498a49148ca8134dae3646769f5\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' clean --all\n",
      "       cwd: C:\\Users\\stari\\AppData\\Local\\Temp\\pip-install-seaubbjf\\torch_03e97498a49148ca8134dae3646769f5\n",
      "  Complete output (2 lines):\n",
      "  running clean\n",
      "  error: [Errno 2] No such file or directory: '.gitignore'\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed cleaning build dir for torch\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -ip (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -ensorflow-gpu (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'e:\\pyhton_verzeichnis\\bib_daten\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\stari\\\\AppData\\\\Local\\\\Temp\\\\pip-install-seaubbjf\\\\torch_03e97498a49148ca8134dae3646769f5\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\stari\\\\AppData\\\\Local\\\\Temp\\\\pip-install-seaubbjf\\\\torch_03e97498a49148ca8134dae3646769f5\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\stari\\AppData\\Local\\Temp\\pip-record-zuaia09y\\install-record.txt' --single-version-externally-managed --compile --install-headers 'e:\\pyhton_verzeichnis\\bib_daten\\Include\\torch'\n",
      "         cwd: C:\\Users\\stari\\AppData\\Local\\Temp\\pip-install-seaubbjf\\torch_03e97498a49148ca8134dae3646769f5\\\n",
      "    Complete output (23 lines):\n",
      "    running install\n",
      "    running build_deps\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\stari\\AppData\\Local\\Temp\\pip-install-seaubbjf\\torch_03e97498a49148ca8134dae3646769f5\\setup.py\", line 225, in <module>\n",
      "        setup(name=\"torch\", version=\"0.1.2.post2\",\n",
      "      File \"e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages\\setuptools\\__init__.py\", line 153, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"e:\\pyhton_verzeichnis\\bib_daten\\lib\\distutils\\core.py\", line 148, in setup\n",
      "        dist.run_commands()\n",
      "      File \"e:\\pyhton_verzeichnis\\bib_daten\\lib\\distutils\\dist.py\", line 966, in run_commands\n",
      "        self.run_command(cmd)\n",
      "      File \"e:\\pyhton_verzeichnis\\bib_daten\\lib\\distutils\\dist.py\", line 985, in run_command\n",
      "        cmd_obj.run()\n",
      "      File \"C:\\Users\\stari\\AppData\\Local\\Temp\\pip-install-seaubbjf\\torch_03e97498a49148ca8134dae3646769f5\\setup.py\", line 99, in run\n",
      "        self.run_command('build_deps')\n",
      "      File \"e:\\pyhton_verzeichnis\\bib_daten\\lib\\distutils\\cmd.py\", line 313, in run_command\n",
      "        self.distribution.run_command(command)\n",
      "      File \"e:\\pyhton_verzeichnis\\bib_daten\\lib\\distutils\\dist.py\", line 985, in run_command\n",
      "        cmd_obj.run()\n",
      "      File \"C:\\Users\\stari\\AppData\\Local\\Temp\\pip-install-seaubbjf\\torch_03e97498a49148ca8134dae3646769f5\\setup.py\", line 51, in run\n",
      "        from tools.nnwrap import generate_wrappers as generate_nn_wrappers\n",
      "    ModuleNotFoundError: No module named 'tools.nnwrap'\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'e:\\pyhton_verzeichnis\\bib_daten\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\stari\\\\AppData\\\\Local\\\\Temp\\\\pip-install-seaubbjf\\\\torch_03e97498a49148ca8134dae3646769f5\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\stari\\\\AppData\\\\Local\\\\Temp\\\\pip-install-seaubbjf\\\\torch_03e97498a49148ca8134dae3646769f5\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\stari\\AppData\\Local\\Temp\\pip-record-zuaia09y\\install-record.txt' --single-version-externally-managed --compile --install-headers 'e:\\pyhton_verzeichnis\\bib_daten\\Include\\torch' Check the logs for full command output.\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (e:\\pyhton_verzeichnis\\bib_daten\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install transformers\n",
    "!pip install truecase\n",
    "!pip install mosestokenizer\n",
    "print(\"done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--model_name', type=str, default='bert-base-multilingual-cased')\n",
    "parser.add_argument('--do_lower_case', type=bool, default=False)\n",
    "parser.add_argument('--language_model', type=str, default='gpt2')\n",
    "parser.add_argument('--mapping', type=str, default='CLP', help='CLP or UMD')\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model_name\": \"bert-base-multilingual-cased\",\n",
      "  \"do_lower_case\": false,\n",
      "  \"language_model\": \"gpt2\",\n",
      "  \"mapping\": \"CLP\",\n",
      "  \"f\": \"C:\\\\Users\\\\stari\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-0a2167df-23e3-4dab-b9d1-6a1194688647.json\"\n",
      "}\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "parser.add_argument('-f')# Dummy parser element\n",
    "args = parser.parse_args()\n",
    "params = vars(args)\n",
    "print(json.dumps(params, indent = 2))\n",
    "\n",
    "\n",
    "print(\"Done\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyemd'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-8-27333741b8e6>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mXMoverScore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mscorer\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mXMOVERScorer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtruecase\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Uni\\Aufnahmen Vorlesung\\SoSe21\\Meta\\Gruppen_Repo\\NLP_Metric\\XMoverScore\\scorer.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtransformers\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mGPT2LMHeadModel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mGPT2Tokenizer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtransformers\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mBertModel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mBertTokenizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mBertConfig\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mscore_utils\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mword_mover_score\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlm_perplexity\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mXMOVERScorer\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Uni\\Aufnahmen Vorlesung\\SoSe21\\Meta\\Gruppen_Repo\\NLP_Metric\\XMoverScore\\score_utils.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0m__future__\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mabsolute_import\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdivision\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprint_function\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mpyemd\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0memd\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mstring\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'pyemd'"
     ]
    }
   ],
   "source": [
    "from XMoverScore.scorer import XMOVERScorer\n",
    "import numpy as np\n",
    "import torch\n",
    "import truecase\n",
    "\n",
    "scorer = XMOVERScorer(args.model_name, args.language_model, args.do_lower_case)\n",
    "\n",
    "def metric_combination(a, b, alpha):\n",
    "    return alpha[0]*np.array(a) + alpha[1]*np.array(b)\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate :\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}